<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Vibeke Bertelsen (Udart) &#187; Blog</title>
	<atom:link href="http://udart.dk/category/blog/feed/" rel="self" type="application/rss+xml" />
	<link>http://udart.dk</link>
	<description>Digital art and motion graphics</description>
	<lastBuildDate>Wed, 20 Jun 2018 10:54:35 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>http://wordpress.org/?v=4.1.1</generator>
	<item>
		<title>Quick tip: Shaders in Sublime Text</title>
		<link>http://udart.dk/2015/06/23/quick-tip-shaders-in-sublime-text/</link>
		<comments>http://udart.dk/2015/06/23/quick-tip-shaders-in-sublime-text/#comments</comments>
		<pubDate>Tue, 23 Jun 2015 10:52:49 +0000</pubDate>
		<dc:creator><![CDATA[Udart]]></dc:creator>
				<category><![CDATA[Blog]]></category>
		<category><![CDATA[Tips and tutorials]]></category>
		<category><![CDATA[GLSL]]></category>
		<category><![CDATA[javascript]]></category>
		<category><![CDATA[regular expression]]></category>
		<category><![CDATA[shader]]></category>
		<category><![CDATA[Sublime Text]]></category>
		<category><![CDATA[Threejs]]></category>
		<category><![CDATA[WebGL]]></category>

		<guid isPermaLink="false">http://udart.dk/?p=503</guid>
		<description><![CDATA[Sublime Text is my favorite text editor and here&#8217;s a quick tip if you&#8217;re working with shaders in three.js. I prefer to store my shaders as a separate file. And to do this in the same way as three.js all shader code must be enclosed in quotes and comma-separated. Enter this in the search and replace boxes in Sublime Text and you have a quick way to prepare your shaders for three.js: Note the &#8216;regular expression&#8217; button must be active.]]></description>
				<content:encoded><![CDATA[<p><a href="http://www.sublimetext.com"  target="_blank">Sublime Text</a> is my favorite text editor and here&#8217;s a quick tip if you&#8217;re working with shaders in <a href="http://threejs.orgthree.js"  target="_blank">three.js</a>.</p>
<p>I prefer to store my shaders as a separate file. And to do this in the same way as three.js all shader code must be enclosed in quotes and comma-separated. Enter this in the search and replace boxes in Sublime Text and you have a quick way to prepare your shaders for three.js:</p>
<p><a href="http://udart.dk/wp-content/Screen-Shot-2015-06-23-at-12.25.48.png" ><img src="http://udart.dk/wp-content/Screen-Shot-2015-06-23-at-12.25.48-300x63.png" alt="Screen Shot 2015-06-23 at 12.25.48" width="300" height="63" class="alignright size-medium wp-image-504" /></a></p>
<p>Note the &#8216;regular expression&#8217; button must be active.</p>
]]></content:encoded>
			<wfw:commentRss>http://udart.dk/2015/06/23/quick-tip-shaders-in-sublime-text/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>What is projection mapping?</title>
		<link>http://udart.dk/2015/03/18/what-is-projection-mapping/</link>
		<comments>http://udart.dk/2015/03/18/what-is-projection-mapping/#comments</comments>
		<pubDate>Wed, 18 Mar 2015 08:50:11 +0000</pubDate>
		<dc:creator><![CDATA[Udart]]></dc:creator>
				<category><![CDATA[Blog]]></category>
		<category><![CDATA[building mapping]]></category>
		<category><![CDATA[MadMapper]]></category>
		<category><![CDATA[projection mapping]]></category>
		<category><![CDATA[video projection]]></category>
		<category><![CDATA[wiki]]></category>

		<guid isPermaLink="false">http://udart.dk/?p=494</guid>
		<description><![CDATA[As Wikipedia states in their definition of projection mapping: &#8220;Projection mapping, also known as video mapping and spatial augmented reality, is a projection technology used to turn objects, often irregularly shaped, into a display surface for video projection. These objects may be complex industrial landscapes, such as buildings.&#8221; With projection mapping one can create interesting visual effects even optical illusions that make the static surface seem to move. Also an important aspect of the experience is the audio that complete the illusion. Many people have seen impressive examples such as this one on a clock tower A number of tools exist that aid with the projection mapping. Madmapper, Blendy and TouchDesigner to name a few. These tools help the aligning of the video projection to fit onto the surface. A list of projection mapping software A mapping tool is not enough however. One will need to prepare graphical content especially [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>As Wikipedia states in their definition of projection mapping:</p>
<blockquote><p>&#8220;Projection mapping, also known as video mapping and spatial augmented reality, is a projection technology used to turn objects, often irregularly shaped, into a display surface for video projection. These objects may be complex industrial landscapes, such as buildings.&#8221;</p></blockquote>
<p>With projection mapping one can create interesting visual effects even optical illusions that make the static surface seem to move. Also an important aspect of the experience is the audio that complete the illusion. Many people have seen impressive examples such as this one on a <a href="https://vimeo.com/15749093"  title="clock tower" target="_blank">clock tower</a> </p>
<p>A number of tools exist that aid with the projection mapping. Madmapper, Blendy and TouchDesigner to name a few. These tools help the aligning of the video projection to fit onto the surface. </p>
<p><a href="http://projection-mapping.org/software/"  target="_blank">A list of projection mapping software</a></p>
<p>A mapping tool is not enough however. One will need to prepare graphical content especially tailored to the shape of the projection surface. This will most often be created in a 3d modelling and animation application such as 3D Studio Max, Blender or Cinema4D to name a few. Here a complete 3D model of the chosen surface will be modelled with all visual details.</p>
<h2>Considerations before planning a projection mapping</h2>
<p>Since the content needs to be tailored to the exact shape of the building or the surface one cannot buy ready made loops for projection mapping. Although I have seen this advertised it is fake and will not create the desired illusion.</p>
<p>Projection mapping is a quite expensive form of entertainment. Apart from the cost of creating the graphics (and sound) there is also the cost of renting video projectors. If you&#8217;re projecting outdoors onto a building you will need one or more big projectors (15.000 &#8211; 20.000 lumen) and also take care that they are protected from the weather. This alone can cost up to 3000$ USD. However this will be cheaper for smaller surfaces.</p>
<p>Also light conditions will have to be taken into account so street lights may need to be turned off. The darker the environment the better or the real shape of the building will be visible and take away from the illusion one is trying to create.</p>
]]></content:encoded>
			<wfw:commentRss>http://udart.dk/2015/03/18/what-is-projection-mapping/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>WebGL experiment: Expose line drawing</title>
		<link>http://udart.dk/2013/12/26/webgl-experiment-expose-line-drawing/</link>
		<comments>http://udart.dk/2013/12/26/webgl-experiment-expose-line-drawing/#comments</comments>
		<pubDate>Thu, 26 Dec 2013 20:49:38 +0000</pubDate>
		<dc:creator><![CDATA[Udart]]></dc:creator>
				<category><![CDATA[Blog]]></category>
		<category><![CDATA[interactive]]></category>
		<category><![CDATA[WebGL]]></category>

		<guid isPermaLink="false">http://www.udart.dk/?p=375</guid>
		<description><![CDATA[Here&#8217;s a WebGL demo I made &#8211; when you click the canvas a hand drawn image slowly appears. Try it out: http://udart.dk/webgl/expose_line_drawing/ The effect is achieved using a shader based technique called reaction diffusion as a mask over the image. The reaction effect &#8216;feeds&#8217; on the line drawing and gradually spreads as far as possible following the black lines. My code builds upon an example by pmneila.]]></description>
				<content:encoded><![CDATA[<p><a href="http://www.udart.dk/wp-content/Screen-Shot-2013-12-26-at-21.08.171.png" ><img class="alignright size-medium wp-image-378" title="Screen Shot 2013-12-26 at 21.08.17" src="http://www.udart.dk/wp-content/Screen-Shot-2013-12-26-at-21.08.171-300x182.png" alt="Screen Shot 2013-12-26 at 21.08.17" width="300" height="182" /></a>Here&#8217;s a WebGL demo I made &#8211; when you click the canvas a hand drawn image slowly appears. Try it out:<br />
<a href="http://udart.dk/webgl/expose_line_drawing/" >http://udart.dk/webgl/expose_line_drawing/</a></p>
<p>The effect is achieved using a shader based technique called reaction diffusion as a mask over the image. The reaction effect &#8216;feeds&#8217; on the line drawing and gradually spreads as far as possible following the black lines. My code builds upon an <a href="http://pmneila.github.io/jsexp/gsimage/"  target="_blank">example by pmneila</a>.</p>
]]></content:encoded>
			<wfw:commentRss>http://udart.dk/2013/12/26/webgl-experiment-expose-line-drawing/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Syphon into the web browser</title>
		<link>http://udart.dk/2013/06/03/syphon-into-the-web-browser/</link>
		<comments>http://udart.dk/2013/06/03/syphon-into-the-web-browser/#comments</comments>
		<pubDate>Mon, 03 Jun 2013 08:50:58 +0000</pubDate>
		<dc:creator><![CDATA[Udart]]></dc:creator>
				<category><![CDATA[Blog]]></category>
		<category><![CDATA[Cool stuff]]></category>

		<guid isPermaLink="false">http://www.udart.dk/?p=345</guid>
		<description><![CDATA[Yes apparently we can have a Syphon input into the web browser. It is a workaround done via Quicktime. So it has some limitations. The biggest limitation being that we can not use the Syphon input as a texture in WebGL. When I did this I prepared a Syphon client in Quartz Composer and converted it to a Quicktime file. Then I put it into my webpage like this: &#60;embed width="400px" height="300px" name="plugin" src="file:///Syphon%20Client%20QC.mov" type="video/quicktime"&#62; It does seem that we can put CSS filters on the Quicktime element which I hadn&#8217;t expected (tested in Safari and Chrome). Like this: &#60;head&#62; &#60;style&#62; .filtered { -webkit-filter: hue-rotate(230deg) saturate(300%) blur(6px); } &#60;/style&#62; &#60;/head&#62; &#60;body&#62; &#60;embed class="filtered" width="400px" height="300px" name="plugin" src="Syphon%20Client%20QC.mov" type="video/quicktime"&#62; &#60;/body&#62; I have also tested the awesome up-and-coming CSS custom filters feature but it does not work on videos or embedded content &#8211; yet. I have a hope that when it is [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>Yes apparently we can have a Syphon input into the web browser. It is a workaround done via Quicktime. So it has some limitations. The biggest limitation being that we can not use the Syphon input as a texture in WebGL. When I did this I prepared a Syphon client in Quartz Composer and converted it to a Quicktime file. Then I put it into my webpage like this:</p>
<p><code>&lt;embed width="400px" height="300px" name="plugin" src="file:///Syphon%20Client%20QC.mov" type="video/quicktime"&gt;</code></p>
<p>It does seem that we can put CSS filters on the Quicktime element which I hadn&#8217;t expected (tested in Safari and Chrome). Like this:<br />
<code><br />
&lt;head&gt;<br />
    &lt;style&gt;<br />
        .filtered {<br />
            -webkit-filter: hue-rotate(230deg)<br />
                            saturate(300%)<br />
                            blur(6px);<br />
        }<br />
    &lt;/style&gt;<br />
&lt;/head&gt;<br />
&lt;body&gt;<br />
    &lt;embed class="filtered" width="400px" height="300px" name="plugin" src="Syphon%20Client%20QC.mov" type="video/quicktime"&gt;<br />
&lt;/body&gt;<br />
</code></p>
<p>I have also tested the awesome up-and-coming <a href="http://adobe.github.io/web-platform/samples/css-customfilters/"  target="_blank">CSS custom filters</a> feature but it does not work on videos or embedded content &#8211; yet. I have a hope that when it is implemented for the video tag it will also work for the embed tag. That would finally give us some control over a Syphon input transforming the geometry and style of it as we please.</p>
<p>So what is this all good for? Well basically I would like to use the web browser as a VJing tool. And for visualists Syphon is such a nice tool so this discovery is a good step in the right direction for creating a VJ tool using browser technology.</p>
<p>For anyone wondering this has nothing to do with streaming a Syphon source. It&#8217;s purely an example that is running on the local machine.</p>
]]></content:encoded>
			<wfw:commentRss>http://udart.dk/2013/06/03/syphon-into-the-web-browser/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
		</item>
		<item>
		<title>Live online remix of the maps at here.com</title>
		<link>http://udart.dk/2013/05/15/live-online-remix-of-the-maps-at-here-com/</link>
		<comments>http://udart.dk/2013/05/15/live-online-remix-of-the-maps-at-here-com/#comments</comments>
		<pubDate>Wed, 15 May 2013 20:53:38 +0000</pubDate>
		<dc:creator><![CDATA[Udart]]></dc:creator>
				<category><![CDATA[Blog]]></category>
		<category><![CDATA[Software]]></category>

		<guid isPermaLink="false">http://www.udart.dk/?p=327</guid>
		<description><![CDATA[A remix could be many things but in this case the word refers to some modifications I made to the maps at here.com in realtime using the Node-Webkit framework. Like this: What you see on the right is a screen-shot of the live and navigable application at here.com but interface elements have been removed and the whole maps has received a colored tint. In other words it&#8217;s possible to modify and change the look and functionality of a live website without copying it to another server or hack the server on which the website resides (don&#8217;t do that, kids!). I made the modifications using simple html and javascript which modifies the website when viewed in my own browser &#8211; or in this case a specialized application made using the Node-Webkit framework. In this video I demonstrate how the modification works: Background As a part of my work with Obscura we [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>A remix could be many things but in this case the word refers to some modifications I made to the maps at <a href="http://here.com"  target="_blank">here.com</a> in realtime using the <a href="https://github.com/rogerwang/node-webkit/wiki"  target="_blank">Node-Webkit</a> framework. Like this:</p>
<p><a href="http://www.udart.dk/wp-content/Maps_before_after.png" ><img src="http://www.udart.dk/wp-content/Maps_before_after.png" alt="Maps_before_after" title="Maps_before_after" width="540" height="181" class="aligncenter size-full wp-image-334" /></a></p>
<p>What you see on the right is a screen-shot of the live and navigable application at here.com but interface elements have been removed and the whole maps has received a colored tint.</p>
<p>In other words it&#8217;s possible to modify and change the look and functionality of a live website without copying it to another server or hack the server on which the website resides (don&#8217;t do that, kids!).<br />
I made the modifications using simple html and javascript which modifies the website when viewed in my own browser &#8211; or in this case a specialized application made using the <a href="https://github.com/rogerwang/node-webkit/wiki"  target="_blank">Node-Webkit</a> framework. </p>
<p>In this video I demonstrate how the modification works:<br />
<iframe src="http://player.vimeo.com/video/66271461" width="500" height="281" frameborder="0" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></p>
<h2>Background</h2>
<p>As a part of my work with Obscura we do visuals for various events. For this one event it would be really appropriate to display some nice slow flyover video on the big screen of 3d maps like the ones you have on Apple maps or Google maps on iOS. I found the maps at here.com and pondered how to get them on the big screen without those navigation buttons while still being able to control camera movements.</p>
<h2>Real time browser remix</h2>
<p>Via javascript it&#8217;s pretty easy to modify the DOM of a web page &#8211; thus controlling how the page is displayed in your browser. and hiding an element or a section only requires one line of code. For instance you can navigate to here.com in the Chrome or Firefox browser, choose the 3D map display and bring up the Developer Tools console. There you enter this line:</p>
<p><code>window.document.getElementById("map-controls").style.display = "none";</code></p>
<p>And voila the navigation button are gone and same goes for the other UI overlays.<br />
Changing the look of the map was easy with CSS filters that have become available in HTML5.</p>
<p>So using the developer tools I also figured out a bit of the code that lies below the surface on here.com and I found some methods that I could trigger and use to navigate the map even with no visible controls. Keyboard shortcuts are already implemented (arrows, shift, + and -) but I didn&#8217;t like the movements &#8211; I thought it was going to fast on a big screen.</p>
<h2>Security Issues</h2>
<p>Problem is I would have to put all this stuff in to the console every time I open the here.com website. And with an accidental reload of the page I would have to do it again.<br />
So I thought about writing a document that opens here.com in a pop up window and then modifies it in the same way as we did above? Well this is called cross site scripting and there are many reasons why browser creators don&#8217;t like that.</p>
<h2>Node-Webkit</h2>
<p>However from other experiments I have become familiar with an application framework called <a href="https://github.com/rogerwang/node-webkit/wiki"  target="_blank">Node-Webkit</a> which provides a handy and quite easy way to create standalone applications using HTML and Javascript. And since node-webkit has a fully functional Chromium (open sourced Chrome) browser embedded I could continue my experiments in Node-webkit. And most importantly &#8211; without any security restrictions. Node-webkit allows you to dig into the DOM and javascript of any webpage you load!</p>
<h2>Results</h2>
<p>Here is the final Node-webkit application I made. To run it simply go to Node-webkit site and grab <a href="https://github.com/rogerwang/node-webkit#downloads"  target="_blank">a binary</a> for your platform then download my file and open it with node-webkit: <a href="http://www.udart.dk/wp-content/maps.nw" >Maps</a><br />
My small app has plenty of bugs (I had one day before the event to figure it out) but feel free to have a look. Simply rename maps.nw to .zip and unpack it.</p>
]]></content:encoded>
			<wfw:commentRss>http://udart.dk/2013/05/15/live-online-remix-of-the-maps-at-here-com/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Getting started with WebGL</title>
		<link>http://udart.dk/2013/03/01/getting-started-with-webgl/</link>
		<comments>http://udart.dk/2013/03/01/getting-started-with-webgl/#comments</comments>
		<pubDate>Fri, 01 Mar 2013 21:54:49 +0000</pubDate>
		<dc:creator><![CDATA[Udart]]></dc:creator>
				<category><![CDATA[Blog]]></category>
		<category><![CDATA[Tips and tutorials]]></category>
		<category><![CDATA[3D graphics]]></category>
		<category><![CDATA[HTML5]]></category>
		<category><![CDATA[javascript]]></category>
		<category><![CDATA[WebGL]]></category>

		<guid isPermaLink="false">http://www.udart.dk/?p=311</guid>
		<description><![CDATA[Here&#8217;s the thing that takes up my spare time right now: WebGL. For me with my web developer background (PHP, javascript, .NET) and my growing interest in realtime 3D graphics it&#8217;s so obvious that I can&#8217;t believe I haven&#8217;t played around with it before. The good thing is that at this point there are plenty of resources for those who want to learn and that it has been implemented in a stable way in some major browsers. The downside is that it&#8217;s not an obvious choice for VJs as it does not integrate with VJ apps. But I&#8217;m sure tools will appear over time to overcome this. Just have a look at some of the mind-blowing visual possibilities WebGL brings for visualists: Lights Ro.me Blast Often when delving into a new programming environment the hard part comes right at the beginning when you try to get a grasp of the [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>Here&#8217;s the thing that takes up my spare time right now: <a href="http://en.wikipedia.org/wiki/WebGL"  target="_blank">WebGL</a>. For me with my web developer background (PHP, javascript, .NET) and my growing interest in realtime 3D graphics it&#8217;s so obvious that I can&#8217;t believe I haven&#8217;t played around with it before. The good thing is that at this point there are plenty of resources for those who want to learn and that it has been implemented in a stable way in some major browsers.<br />
The downside is that it&#8217;s not an obvious choice for VJs as it does not integrate with VJ apps. But I&#8217;m sure tools will appear over time to overcome this.</p>
<p>Just have a look at some of the mind-blowing visual possibilities WebGL brings for visualists:<br />
<a href="http://thenextweb.com/shareables/2011/11/26/lights-an-amazing-display-of-webgl-power-kiss-your-flash-goodbye/"  target="_blank">Lights</a><br />
<a href="http://www.ro.me/tech/"  target="_blank">Ro.me</a><br />
<a href="http://www.webgl.com/2012/10/webgl-demo-blast/"  target="_blank">Blast</a><br />
Often when delving into a new programming environment the hard part comes right at the beginning when you try to get a grasp of the architecture of things and the tools needed. I have been playing around with webGL for about a week now and I am slowly getting over that first stony hillside I needed to climb before being able to code anything useful.</p>
<p>So I thought I&#8217;d share what I found useful along the way in order to get up and running.</p>
<h3>1. Programming environment</h3>
<p>In theory all you need is a text editor and a browser. But I know from experience that a real code editor is useful to help keep everything readable. So far I am quite pleased with <a href="http://www.sublimetext.com/"  target="_blank">Sublime Text</a>. As for the browser I chose <a href="https://www.google.com/intl/da/chrome/browser/"  target="_blank">Chrome</a> for development, but it could probably just as well be <a href="http://www.mozilla.org/en-US/firefox/new/"  target="_blank">Firefox</a>. From what I&#8217;ve heard Opera and Safari do not quite live up to the others yet and as for Internet Explorer &#8211; <a href="http://talk.webplatform.org/forums/index.php/506/when-will-internet-explorer-support-webgl"  target="_blank">who knows?</a>. Make sure to have the latest version of the browser.</p>
<h3>2. Web server</h3>
<p>Yes a web server is needed, loading up pages by simply opening them locally is only going to work for the simplest of coding examples. Fortunately I am  on a Mac and got a long way using the built in Python http-server. Here&#8217;s a quick how-to:<br />
Open the Terminal app, write &#8216;cd &#8216; and drag the folder with your code files into the Terminal window. Now it says &#8216;cd /Users/You/Path/To/Your/Folder/&#8217;. Make sure there&#8217;s a space after cd. Enter. Then write &#8216;python -mSimpleHTTPServer&#8217;. Enter. Now the Terminal should respond &#8216;Serving HTTP on 0.0.0.0 port 8000&#8242;. Go into Chrome and write &#8216;http://localhost:8000&#8242; as the address. You should now see the contents of your folder as clickable links.</p>
<h3>3. WebGL API</h3>
<p>webGL is supported by the above mentioned browsers out of the box. However I use an API for accessing webGL as I find the objects and functions of the API hide some of the complexities and provide me with helpful shortcuts to get things done. One of the most popular at the moment seems to be <a href="http://mrdoob.github.com/three.js/"   target="_blank">Three.js</a> and so far I am enjoying using it a lot. There are a lot of good resources and examples on Three.js on the net right now.</p>
<h3>4. Getting started with three.js</h3>
<p>First I followed <a href="http://www.aerotwist.com/tutorials/getting-started-with-three-js/"   target="_blank">this tutorial</a>. Then I tried to code something myself. I found out that the <a href="http://mrdoob.github.com/three.js/docs/"  target="_blank">documentation</a> is of some use but it&#8217;s very incomplete at the moment. So I did what was recommended and dug into the three.js examples (they are in the examples folder of the three.js download). I start out by looking at an example that does something close to what I want to achieve and then I copy the file and start messing with the code. Unfortunately I have often found the examples to be overly complex &#8211; especially when I started out &#8211; things are starting to make more sense now. I keep peeling away the stuff that I don&#8217;t need in the code, while continually checking in the browser what effect my change is having until I have a minimal working example. Then and only then do I start adding my own code. I may also try to combine code from different examples to achieve what I want.</p>
<h3>5. Debugging javascript</h3>
<p>WebGL is all about javascript and fortunately Chromes developer tools are really good for telling what&#8217;s going on and what is going wrong. cmd+option+I brings up the panel. Console shows the error messages but I have also had good use of the Watch Expressions and the Break Points. Here&#8217;s a good article to get started with the <a href="http://www.netmagazine.com/tutorials/javascript-debugging-beginners"  target="_blank">debugger tools</a>.</p>
<h3>6. Figuring out the error messages</h3>
<p>For many things I understand what&#8217;s wrong by simply clicking the link in the console and see where in the code the error is. But for the more cryptic error messages Google is my friend. It may seem obvious but simply googling &#8216;webGL three.js&#8217; + the error message will often bring up something useful. Especially the questions and answers on stackoverflow.com &#8211; no wonder as the developer of three.js moved all support to this site. For some browser specific errors searching for &#8216;chrome&#8217; + error text will bring up an answer.</p>
<h3>7. What WebGL isn&#8217;t</h3>
<p>First of all WebGL builds upon OpenGL but it&#8217;s not the same. So reading up OpenGL won&#8217;t be directly applicable &#8211; especially so if you&#8217;re using an API like three.js. OpenGL code examples from other contexts may be portable but not without some translation. If you&#8217;re new to the whole realm of realtime 3D graphics including openGL it would probably be useful to read a primer on the general concepts &#8211; although one big advantage of three.js lies in the way it uses words and concepts that will be familiar to you if you have played with 3D applications such as 3D Studio, Maya or Cinema4D.</p>
<p>So that&#8217;s it from me for now. I don&#8217;t offer a complete webGL tutorial just these few tips for now. If you are already up and running with WebGL feel free to add in the comments any other similar tips that helped you when you started out.</p>
]]></content:encoded>
			<wfw:commentRss>http://udart.dk/2013/03/01/getting-started-with-webgl/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Finding the right beat</title>
		<link>http://udart.dk/2012/04/06/finding-the-right-beat/</link>
		<comments>http://udart.dk/2012/04/06/finding-the-right-beat/#comments</comments>
		<pubDate>Fri, 06 Apr 2012 18:45:24 +0000</pubDate>
		<dc:creator><![CDATA[Udart]]></dc:creator>
				<category><![CDATA[Blog]]></category>
		<category><![CDATA[Tips and tutorials]]></category>

		<guid isPermaLink="false">http://www.udart.dk/?p=291</guid>
		<description><![CDATA[At those (admittedly few) occassions when I VJ alongside DJ I have often wished for a tool that would detect the tempo of the music for me. The more I searched for a Mac based solution the more I realized there is some pretty complex music analysis behind beat detection and that few or no freeware tools existed. Vj apps seem to have settled on a tap-the-beat solution and most of the existing BPM detectors are not real time as they only operate on prerecorded audio files. Then someone posted a link to this ingenious little app in the Modul8 forums and I have been using it ever since. It picks up the beat after a few seconds and it&#8217;s pretty accurate &#8211; as long as there is a steady discernible beat to the music of course. Waveclock You try it out in demo mode (and click away a dialog [&#8230;]]]></description>
				<content:encoded><![CDATA[<p><div id="attachment_294" style="width: 198px" class="wp-caption alignright"><a href="http://www.udart.dk/wp-content/Screen-Shot-2012-04-06-at-8.43.37-PM.png" ><img src="http://www.udart.dk/wp-content/Screen-Shot-2012-04-06-at-8.43.37-PM.png" alt="Waveclock - BPM detection" title="Waveclock" width="188" height="198" class="size-full wp-image-294" /></a><p class="wp-caption-text">Waveclock - BPM detection</p></div>At those (admittedly few) occassions when I VJ alongside DJ I have often wished for a tool that would detect the tempo of the music for me. The more I searched for a Mac based  solution the more I realized there is some pretty complex music analysis behind beat detection and that few or no freeware tools existed. Vj apps seem to have settled on a tap-the-beat solution and most of the existing BPM detectors are not real time as they only operate on prerecorded audio files.<br />
Then someone posted a link to this ingenious little app in the Modul8 forums and I have been using it ever since. It picks up the beat after a few seconds and it&#8217;s pretty accurate &#8211; as long as there is a steady discernible beat to the music of course.</p>
<p><a href="http://wavesum.net/waveclock-audio-to-midi-clock.html<br />
" target="_blank">Waveclock</a></p>
<p>You try it out in demo mode (and click away a dialog box every twenty minutes). It&#8217;s an independent app so apart from Modul8 it ought to work with any VJ app that supports midi clock.</p>
<p>1. First you go to the Waveclock preferences and select your microphone or line-in for the input. And some midi channel for the output &#8211; IAC Driver for instance. </p>
<p>2. Then in Modul8 or your other VJ app you go to preferences and confirm that IAC Driver is activated as a midi input.</p>
<p>3. Then (in Modul8) you activate the BPM modul and click &#8216;use midi clock&#8217;.</p>
]]></content:encoded>
			<wfw:commentRss>http://udart.dk/2012/04/06/finding-the-right-beat/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Using cues, timelines and VJ software for performances</title>
		<link>http://udart.dk/2011/10/14/using-cues-timelines-and-vj-software-for-performances/</link>
		<comments>http://udart.dk/2011/10/14/using-cues-timelines-and-vj-software-for-performances/#comments</comments>
		<pubDate>Fri, 14 Oct 2011 12:43:52 +0000</pubDate>
		<dc:creator><![CDATA[Udart]]></dc:creator>
				<category><![CDATA[Blog]]></category>
		<category><![CDATA[Tips and tutorials]]></category>
		<category><![CDATA[Blackmagic Intensity]]></category>
		<category><![CDATA[cue list]]></category>
		<category><![CDATA[Matrox]]></category>
		<category><![CDATA[midi]]></category>
		<category><![CDATA[Modul8]]></category>
		<category><![CDATA[Qlab]]></category>
		<category><![CDATA[theatre]]></category>

		<guid isPermaLink="false">http://www.udart.dk/?p=283</guid>
		<description><![CDATA[These days as a part of the Obscura crew I am ofting doing visual shows that have more in common with theatre productions than traditional VJing. Often there is some sort of script for a show or a piece of music that is rehearsed. For these types of jobs I have found good use for the application called QLab which is great for triggering a pre planned sequence of events. Actually the whole point of QLab is to line up a sequence of audio, video files or other types of events and being able to trigger them with a simple &#8216;Go&#8217; button at the exact right time during the show. QLab was originally developed with audio in mind and has later been extended with video features so it does not have many features as VJ applications when it comes to live manipulations of images and video. But for those of [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>These days as a part of the Obscura crew I am ofting doing visual shows that have more in common with theatre productions than traditional VJing. Often there is some sort of script for a show or a piece of music that is rehearsed. For these types of jobs I have found good use for the application called <a target="_blank" href="http://figure53.com/qlab/" >QLab</a> which is great for triggering a pre planned sequence of events.</p>
<p>Actually the whole point of QLab is to line up a sequence of audio, video files or other types of events and being able to trigger them with a simple &#8216;Go&#8217; button at the exact right time during the show.<br />
QLab was originally developed with audio in mind and has later been extended with video features so it does not have many features as VJ applications when it comes to live manipulations of images and video. But for those of us who sometimes wish for a timeline in our favorite VJ application, QLab may be an option if you set it up to run alongside your VJ app.<br />
For our shows we typically use Modul8 and I found two ways to achieve this.</p>
<p>1. Capturing the video output of QLab and using it as input in Modul8. This is done with two computers &#8211; one with a video capture card such as the <a target="_blank" href="http://www.blackmagic-design.com/products/intensity/" >Blackmagic Intensity</a> hardware or the <a target="_blank" href="http://www.matrox.com/video/en/products/pc/mxo2_family/mxo2_mini/" >Matrox MXO2 mini</a> and the other computer running QLab. With this method you run some images or videos using QLab and you are then able to manipulate them live in Modul8 as you would do with any other source.</p>
<p>2. Setting up QLab to send midi and mapping the buttons in Modul8 so that they respond to the midi commands. This can be done using one computer running both apps or using two computers and a midi connection between them. In this scenario QLab is merely the &#8216;conductor&#8217; telling Modul8 what to do. Modul8 holds all the images or videos used.</p>
<p><a href="http://www.udart.dk/wp-content/qlab-setup.png" ><img src="http://www.udart.dk/wp-content/qlab-setup.png" alt="qlab setup" title="qlab setup" width="540" height="363" class="alignnone size-full wp-image-286" /></a></p>
<p>The advantage of these two methods is that you have some way of combining improvised VJing with a sequence of planned cues. For instance &#8211; as we did recently you can use the first method to trigger a series of slides containing the lyrics of a song and then use Modul8 to distort and manipulate them. Furthermore as this setup involves two computers two people are able to share this task &#8211; one person triggering the lyrics at the right time and one person adding effects. This could be done using any VJ application that is compatible with the video capture card not just Modul8.</p>
]]></content:encoded>
			<wfw:commentRss>http://udart.dk/2011/10/14/using-cues-timelines-and-vj-software-for-performances/feed/</wfw:commentRss>
		<slash:comments>4</slash:comments>
		</item>
		<item>
		<title>Using Unity3D for mapping</title>
		<link>http://udart.dk/2011/06/09/using-unity3d-for-mapping/</link>
		<comments>http://udart.dk/2011/06/09/using-unity3d-for-mapping/#comments</comments>
		<pubDate>Thu, 09 Jun 2011 09:51:54 +0000</pubDate>
		<dc:creator><![CDATA[Udart]]></dc:creator>
				<category><![CDATA[Blog]]></category>
		<category><![CDATA[Portfolio]]></category>
		<category><![CDATA[mapping]]></category>
		<category><![CDATA[Obscura]]></category>
		<category><![CDATA[Syphon]]></category>
		<category><![CDATA[Unity3D]]></category>
		<category><![CDATA[video art]]></category>

		<guid isPermaLink="false">http://www.udart.dk/?p=269</guid>
		<description><![CDATA[The above video documents a recent project Obscura did. Actually I was mostly on another project at the time but I followed with great interest the work that my colleagues Frederik and Kasper did here. For all of us this installation was a learning experience in using Unity 3D for mapping onto a spherical object. It took a bit of trial and error but Frederik and Kasper decided to make a workshop out of it instead of worrying too much about the finished result. They ended up with these little creatures created in Open Frameworks which were piped into Unity 3D via Syphon. They then made a Unity app for mapping onto the sphere. A regular 3D mapped rendering would not do here, as the small boids react to the presence of people in the room via a motion tracking camera. Using Unity went resonably well &#8211; it has a [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>The above video documents a recent project Obscura did. Actually I was mostly on another project at the time but I followed with great interest the work that my colleagues Frederik and Kasper did here. For all of us this installation was a learning experience in using Unity 3D for mapping onto a spherical object. It took a bit of trial and error but Frederik and Kasper decided to make a workshop out of it instead of worrying too much about the finished result.<br />
They ended up with these little creatures created in Open Frameworks which were piped into Unity 3D via Syphon. They then made a Unity app for mapping onto the sphere. A regular 3D mapped rendering would not do here, as the small boids react to the presence of people in the room via a motion tracking camera.<br />
Using Unity went resonably well &#8211; it has a bit of a learning curve, but it definitely has potential for installations that combine live interactivity with mapping, although they ran into some issues that stem from the fact that this is created as a game engine and not a mapping tool.<br />
We feel that we have only just scratched the surface here. In tandem with Syphon you could use Unity to map all sorts of live input onto complex shapes. </p>
]]></content:encoded>
			<wfw:commentRss>http://udart.dk/2011/06/09/using-unity3d-for-mapping/feed/</wfw:commentRss>
		<slash:comments>1</slash:comments>
		</item>
		<item>
		<title>Developing visuals synced to a music composition</title>
		<link>http://udart.dk/2010/04/20/developing-visuals-synced-to-a-music-composition/</link>
		<comments>http://udart.dk/2010/04/20/developing-visuals-synced-to-a-music-composition/#comments</comments>
		<pubDate>Tue, 20 Apr 2010 09:29:38 +0000</pubDate>
		<dc:creator><![CDATA[Udart]]></dc:creator>
				<category><![CDATA[Blog]]></category>
		<category><![CDATA[Portfolio]]></category>
		<category><![CDATA[Max/MSP]]></category>
		<category><![CDATA[midi]]></category>
		<category><![CDATA[Modul8]]></category>

		<guid isPermaLink="false">http://www.udart.dk/?p=175</guid>
		<description><![CDATA[Recently I have had the pleasure of working with Linda Edsjö a classically trained percussionist and composer Simon Christensen in developing visuals for a piece of modern compositional music. The project was unusual for me as we decided to try to connect the visuals computer with the computer that was running the musical backing track. That way it was possible to obtain a perfect sync Â between music and image. The music was composed as a piece in the Max/MSP software and this was linked to Modul8 (the visuals) through midi. The music software was sending midi on every beat and another midi signal whenever the music entered a new section of the piece. To achieve the result I wanted I had to program two small modules for Modul8. These modules were in charge of turning layers on and off, applying effects and switching between images. Excerpt from percussion concert 7 [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>Recently I have had the pleasure of working with Linda Edsjö a classically trained percussionist and composer Simon Christensen in developing visuals for a piece of modern compositional music. The project was unusual for me as we decided to try to connect the visuals computer with the computer that was running the musical backing track. That way it was possible to obtain a perfect sync Â between music and image.</p>
<p>The music was composed as a piece in the Max/MSP software and this was linked to Modul8 (the visuals) through midi. The music software was sending midi on every beat and another midi signal whenever the music entered a new section of the piece.</p>
<p>To achieve the result I wanted I had to program two small modules for Modul8. These modules were in charge of turning layers on and off, applying effects and switching between images.</p>
<p><object classid="clsid:d27cdb6e-ae6d-11cf-96b8-444553540000" width="400" height="300" codebase="http://download.macromedia.com/pub/shockwave/cabs/flash/swflash.cab#version=6,0,40,0"><param name="allowfullscreen" value="true" /><param name="allowscriptaccess" value="always" /><param name="src" value="http://vimeo.com/moogaloop.swf?clip_id=11073072&amp;server=vimeo.com&amp;show_title=1&amp;show_byline=1&amp;show_portrait=0&amp;color=&amp;fullscreen=1" /><embed type="application/x-shockwave-flash" width="400" height="300" src="http://vimeo.com/moogaloop.swf?clip_id=11073072&amp;server=vimeo.com&amp;show_title=1&amp;show_byline=1&amp;show_portrait=0&amp;color=&amp;fullscreen=1" allowscriptaccess="always" allowfullscreen="true"></embed></object></p>
<p><a target="_blank" href="http://vimeo.com/11073072" >Excerpt from percussion concert 7 April 2010</a> from <a target="_blank" href="http://vimeo.com/user702278" >Udart (Vibeke Bertelsen)</a> on <a target="_blank" href="http://vimeo.com" >Vimeo</a>.</p>
<p>[nggallery id=3]</p>
]]></content:encoded>
			<wfw:commentRss>http://udart.dk/2010/04/20/developing-visuals-synced-to-a-music-composition/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
	</channel>
</rss>
